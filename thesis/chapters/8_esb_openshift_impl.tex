\chapter{Implementation ESB in Openshift}
\label{cha:esbi}
This chapter will discuss the implemented prototype, which has been designed in Chapter \vref{cha:esboc}. The implemented prototype uses a lot of technologies and specifications, which are beyond the scope of tis thesis, therefore this thesis will focus on the most important implementation parts. A focus will be set on the implementation of the aspects discussed in Section \vref{sec:esboc-aspects}, which ensure that a integration service can be managed properly in a Openshift Cluster. 
\\ \\
The integration services are implemented as microservice, which run as standalone applications on the Openshift Cluster, with their own life cycle. The integration services communicate via REST with each other, whereby each service provides a proper managed public API. The code bases of the integration services are managed separately, which completely de-couples the integration service from each other.  
\\ \\
As the prototype illustrates, the ESB is now represented by Openshift, which acts as the platform for the hosted integration services. The hosted integration services are implemented as microservices and are running in Docker Containers as standalone applications. Horizontal scaling and the distribution of the services over multiple hosts are now possible. Section \vref{sec:esbi-openshift} will discuss the implemented Openshift resources, which are used to define and manage the Openshift Project.
\\ \\
Is is assumed, that the reader is familiar with Java Enterprise Development, Maven and microservices. The implemented prototype is available on Github \footnote{https://github.com/cchet-thesis-msc/prototype}. The repository contains a README file, which describes how to setup the prototype. 

\section{Microservice Technologies}
\label{sec:esbi-technolody-fis}
The following sections will give a brief introduction about the most important technologies used to implement the integration services. Each implemented service uses the same technologies and is build the same way, because no matter what the concrete purpose of the service is, they all have to be integrated and run the same way on a Openshift Cluster.

\subsection{JBoss Fuse Integration Services 2.0}
\label{sec:esbi-technology-fis}
JBoss Fuse Integration Services 2.0 is a set of tooling for developing integration services running on a Openshift Cluster. It provides Openshift integrations for different frameworks such as Spring Boot, Karaf or Camel. The services are started via an Java-Agent such as Prometheus or Jolokia, which are used to monitor the service during runtime. Additionally to provided Openshift resources, a Maven Plugin is provided, which allows to interact with the Openshift Cluster during a Maven build. JBoss Fuse Integration Services 2.0 allows developers to interact with a Openshift Cluster in a way like developers did before with an application server \cite{Prometheus2018, Jolokia2018}.

\subsection{Wildfly Swarm}
\label{sec:esbi-technology-swarm}
Wildly Swarm is the JEE answer to Spring Boot, and is a framework, which allows to package an application into an Uber-JAR. An Uber-JAR is a packaged standalone application, which can be started with the command \inlineJava{java -jar}. During the packaging, only those components of an application server are packaged, which are referenced and needed by the application. The application can then be started via \inlineBash{java -jar app.jar}, whereby the application server is bootstrapped programmatically.  The application deployment artifact is a JAVA Web-Archive, which could be hosted in any application server environment, which provides all of the referenced dependencies \cite{WildflySwarm2018}. 

\subsection{Fabric8}
\label{sec:esbi-technology-f8}
Fabric8 is an integrated development platform for developing applications on Kubernetes. Fabric8 provides the Maven Plugin for the JBoss Fuse Integration Services 2.0, and focuses on building Docker Images, managing Kubernetes or Openshift resources and deploying Java applications on Kubernetes or Openshift Clusters \cite{Fabric82018}.
\\ \\
The next Section will discuss the implementations of the microservice aspects discussed in Section \vref{sec:esboc-aspects}.

\section{Security}
\label{sec:esbi-security}
The integration services are secured with OAuth, and authenticate their clients via Keycloak. Keycloak is used as the authentication service, and is a very popular open source identity and authentication application. Wildfly Swarm provides an integration into Keycloak via the Keycloak-Adapter, which only needs to be added as a dependency to the Maven POM and to be configured.

\subsection{Service Implementation}
\label{sec:esbi-security-service}
This section will discuss the implementation of the security in the service implementations. Listing \vref{ls:esboi-security-pom} shows the dependency, which brings in the Keycloak Adapter, integrates itself into the Java Web-Security mechanisms, and can therefore be configured with Java Web-Security security constraints.
\begin{listing}
	\xmlFile{\sourceDir/maven-keycloak-swarm.xml}
	\caption{Wildfly Swarm Keycloak dependency in pom.xml}
	\label{ls:esboi-security-pom}
\end{listing}

Listing \vref{ls:esboi-security-yaml} shows an excerpt of the Wildfly Swarm configuration file project-stages.yml, which configures the security constraints for the REST-Endpoint.

\begin{listing}
	\yamlFile{\sourceDir/project-stages-security.yml}
	\caption{Security configuration in project-stages.yml}
	\label{ls:esboi-security-yaml}
\end{listing}

The following two listings are excerpts of the deployment.yml Openshift Template, which is managed in the service code base. Listing \vref{ls:esboi-security-oc-deployment-volume-secret} shows the specification of the secret injection into a Docker Volume. The secrets are injected as files, whereby the file name represents the secret key and the file content represents the secret value. Therefore, that the secrets are managed externally, the developers need to provide the secret name for the service deployment configuration. In this case an expression is used, which can be replaced by Maven Properties, whereby the Maven Properties can be provided in the pom.xml or provided/overwritten by Java Options, during the build process.

\begin{listing}
	\yamlFile{\sourceDir/deployment-volume-secret.yml}
	\caption{Configuration of the secret injection}
	\label{ls:esboi-security-oc-deployment-volume-secret}
\end{listing}

Listing \vref{ls:esboi-security-oc-deployment-volume-mount} show the specification of the mount of the Docker Volume, which provides the secrets. The mount path is also represented by a Maven Property, because this path is also used in the project-stages.yml file, where it points to the service configuration source for the productive stage. The secrets consumed by the services are used the same way as non-sensitive configurations, which are discussed in Section \vref{sec:esbi-configuration}.

\begin{listing}
	\yamlFile{\sourceDir/deployment-volume-secret-container.yml}
	\caption{Configuration volume mount}
	\label{ls:esboi-security-oc-deployment-volume-mount}
\end{listing}

\subsection{Openshift Implementation}
\label{sec:esbi-security-openshift}
This section will discuss the Openshift implementation, whereby the implementation is represented by a shell script, which manages the secrets. The secrets are managed outside the code bases of the integration services.
\\ \\
Listing \vref{ls:esboi-security-oc-secret} shows the Openshift CLI-Commands, which are used to create the secrets. The first command creates a secret from literal values which is used by a client service to retrieve authentication tokens. The second command creates a secret from a file, whereby the filename is the secret key and the content is the secret value, which is used by the Keycloak Adapter to validate authentication tokens provided by the clients. 

\begin{listing}
	\bashFile{\sourceDir/bash-oc-secret.txt}
	\caption{Openshift CLI command for creating the secret}
	\label{ls:esboi-security-oc-secret}
\end{listing}

The discussed implementations are the necessary implementations on the Service and Openshift side, to secure services hosted on a Openshift Cluster. No infrastructure code is necessary, only configuration. The following section will discuss the configuration of the integration services, which can be applied to the security as well, because secrets in Openshift are used in the service implementations the same way as configuration parameters.

\section{Configuration}
\label{sec:esbi-configuration}
The integration services use the MicroProfile Config-API to be configurable for multiple stages by exposing all necessary configuration parameters and to be able to consume configuration parameters from different configuration sources via injection. Developers are bound to the configuration or secret name, keys and their value type, but developers are not bound to the configuration or secret source, which allows to provide configurations from different sources and for different stages. 

\subsection{Service Implementation}
\label{sec:esbi-config-service}
This section will discuss the implementation of the configuration definition and usage. Listing \vref{ls:esboi-config-pom} shows the dependency, which brings in the MicroProfile Config-API and implementations to enable injectable configurations.
 
\begin{listing}
	\xmlFile{\sourceDir/maven-microprofile-config.xml}
	\caption{Wildfly Swarm MicroProfile-Config dependency in pom.xml}
	\label{ls:esboi-config-pom}
\end{listing}

Listing \vref{ls:esboi-config-project-stages-dev} shows the definition of the configuration source with the name \mentionedtext{app.secrets} for the development stage, whereby the configuration properties are provided hard coded.

\begin{listing}
	\bashFile{\sourceDir/project-stages-micro-config-dev.yml}
	\caption{Hard coded configuration for development stage}
	\label{ls:esboi-config-project-stages-dev}
\end{listing}

Listing \vref{ls:esboi-config-project-stages-prod} shows the definition of the configuration source with the name \mentionedtext{app.secrets} for the production stage, whereby the configurations are loaded via a directory. The directory location is represented by an Maven Property, because its used in multiple configuration files, as already discussed in Section \vref{sec:esbi-security-service}. The MicroProfile Config-API and implementations will load files in this directory by using the filename as the key and the content as the value.

\begin{listing}
	\yamlFile{\sourceDir/project-stages-micro-config-prod.yml}
	\caption{External configuration for production stage}
	\label{ls:esboi-config-project-stages-prod}
\end{listing}

Listing \vref{ls:esboi-config-inject} shows the injection of the Keycloak Secrets into a CDI Bean, whereby the actual configuration source, the configurations are retrieved from, is unknown. The injected configuration properties are retrieved from a Openshift Secret, but are used in source code the same way as configurations. The Keycloak Secrets are used to retrieve authentication tokens for the REST calls. 

\begin{listing}
	\javaFile{\sourceDir/java-config-inject.java}
	\caption{Injection of Keycloak configuration parameters}
	\label{ls:esboi-config-inject}
\end{listing}

\subsection{Openshift Implementation}
\label{sec:esbi-config-openshift}
The Openshift implementation has already been covered by Section \vref{sec:esbi-security-openshift}, because configurations and secrets are injected into Docker Containers the same way, and the configuration shown in this section are actual retrieved from a Openshift Secret. 

\section{Tracing}
\label{sec:esbi-tracing}
The integration services use the MicroProfile OpenTracing-API to provide tracing data to a central tracing service. Jaeger\footnote{https://www.jaegertracing.io/} is used as the tracing service, which collects all tracing data and provides a GUI for analyzing traces. 

\subsection{Service Implementation}
\label{sec:esbi-tracing-service}
This section will discuss the implementation of the service tracing. Listing \vref{ls:esboi-tracing-pom} shows the dependency, which brings in the MicroProfile OpenTracing-API and implementations to enable tracing. 

\begin{listing}
	\xmlFile{\sourceDir/maven-microprofile-opentracing.xml}
	\caption{Wildfly Swarm MicroProfile-OpenTracing dependency in pom.xml}
	\label{ls:esboi-tracing-pom}
\end{listing}

Listing \vref{ls:esboi-tracing-project-stages} shows the configuration for the integration into an external tracing service, whereby the configuration parameters are provided by Maven Properties, environment variables and constants. The configuration properties are created as System Properties by Wildfly Swarm, whereby  expressions like \mentionedtext{\$\{env.JAEGER\_PORT\}} are resolved during startup.

\begin{listing}
	\yamlFile{\sourceDir/project-stages-opentracing.yml}
	\caption{Configuration for integration into tracing service}
	\label{ls:esboi-tracing-project-stages}
\end{listing}

Listing \vref{ls:esboi-tracing-java} shows a class which is annotated with \inlineJava{@Traced} on class level, which enables tracing for all methods within this class. The annotation \inlineJava{@Traced} enables an interceptor, which implements the tracing logic. 

\begin{listing}
	\javaFile{\sourceDir/java-tracing.java}
	\caption{Enable tracing for a class}
	\label{ls:esboi-tracing-java}
\end{listing}

A trace is a set of so called spans, whereby a span represents one call in a call chain and contains meta-data of the call such as call duration. The interceptor creates a new span for each call and appends the created span to an existing parent span, or the created span is the parent span. 

\subsection{Openshift Implementation}
\label{sec:esbi-tracing-openshift}
The communication between the integration services and tracing service is done via UDP protocol, and therefore Openshift does need any special configuration.

\section{Logging}
\label{sec:esbi-logging}
The integration services provide logging to a central log aggregation service. Graylog\footnote{https://www.graylog.org/} is used as the log aggregation service, which collects all logging data and provides a GUI for analyzing logs.
\newpage

\subsection{Service Implementation}
\label{sec:esbi-logging-service}
This section will discuss the implementation of the service logging. Listing \vref{ls:esboi-logging-pom} shows the dependencies, which bring in the logging implementations. SLF4J\footnote{https://www.slf4j.org/} has been chosen as the logging facade, whereby an integration in Wildfly Swarm used JBoss Logging is provided by SLF4J.

\begin{listing}
	\xmlFile{\sourceDir/maven-swarm-logging.xml}
	\caption{Wildfly Swarm logging dependencies in pom.xml}
	\label{ls:esboi-logging-pom}
\end{listing}

The following listings are part of the project-stages.yml configuration file and configure logging for different stages. Listing \vref{ls:esboi-logging-format-project-stages} shows the configuration of the logging format, which uses Mapped Diagnostic Context (MDC) parameters to mark a log entry with the transaction id. The configured formatter is used over all stages.

\begin{listing}
	\yamlFile{\sourceDir/project-stages-logging-format.yml}
	\caption{Configuration of the logging format}
	\label{ls:esboi-logging-format-project-stages}
\end{listing}

Listing \vref{ls:esboi-logging-dev-project-stages} shows the logging configuration for the development stage.

\begin{listing}
	\yamlFile{\sourceDir/project-stages-logging-dev.yml}
	\caption{Configuration of the logging for development stage}
	\label{ls:esboi-logging-dev-project-stages}
\end{listing}

Listing \vref{ls:esboi-logging-prod-project-stages} shows the configuration of the logging for the production stage, where the service is contributing its logs to a central log aggregation service. A Syslog logging handler is configured, which sends the logs to the log aggregation service via the SYSLOG\footnote{https://tools.ietf.org/html/rfc5424} protocol.

\begin{listing}
	\yamlFile{\sourceDir/project-stages-logging-prod.yml}
	\caption{Configuration of the logging for production stage}
	\label{ls:esboi-logging-prod-project-stages}
\end{listing}

Listing \vref{ls:esboi-logging-java-transaction-id} shows the implementation of the interface \mentionedtext{ContainerRequestFilter}, which is used to caputre the trace transaction id on a REST Endpoint. The implementation is depending on the Uber MicroProfile OpenTracing-API implementation, because the specification does not provide an transaction id yet.

\begin{listing}
	\javaFile{\sourceDir/java-logging-tracing-id.java}
	\caption{Capture of tracing id on REST Endpoint}
	\label{ls:esboi-logging-java-transaction-id}
\end{listing} 

Listing \vref{ls:esboi-logging-java-producer} shows the CDI Producer for the logger instance. The logger is produced for the Dependent Scope, which means that the producer method gets called for each injection point of each CDI Bean.

\begin{listing}
	\javaFile{\sourceDir/java-logging-producer.java}
	\caption{Logging instance CDI Producer}
	\label{ls:esboi-logging-java-producer}
\end{listing} 


\subsection{Openshift Implementation}
\label{sec:esbi-logging-openshift}

\section{Fault Tolerance}
\label{sec:esbi-fault}

\subsection{Service Implementation}
\label{sec:esbi-fault-service}

\subsection{Openshift Implementation}
\label{sec:esbi-fault-openshift}

\section{API Management}
\label{sec:esbi-api}

\subsection{Service Implementation}
\label{sec:esbi-api-service}

\subsection{Openshift Implementation}
\label{sec:esbi-api-openshift}

\section{Openshift Project}
\label{sec:esbi-openshift}

\subsection{Configuration}
\label{sec:esbi-openshift-config}

\subsection{Secrets}
\label{sec:esbi-openshift-secrets}

