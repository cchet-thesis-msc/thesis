\chapter{Implementation ESB in Openshift}
\label{cha:esbi}
This chapter will discuss the implemented prototype, which has been designed in Chapter \vref{cha:esboc}. The implemented prototype uses a lot of technologies and specifications, which are beyond the scope of tis thesis, therefore this thesis will focus on the most important implementation parts. A focus will be set on the implementation of the aspects discussed in Section \vref{sec:esboc-aspects}, which ensure that a integration service can be managed properly in a Openshift Cluster. 
\\ \\
The integration services are implemented as microservice, which run as standalone applications on the Openshift Cluster, with their own life cycle. The integration services communicate via REST with each other, whereby each service provides a proper managed public API. The code bases of the integration services are managed separately, which completely de-couples the integration service from each other.  
\\ \\
As the prototype illustrates, the ESB is now represented by Openshift, which acts as the platform for the hosted integration services. The hosted integration services are implemented as microservices and are running in Docker Containers as standalone applications. Horizontal scaling and the distribution of the services over multiple hosts are now possible. Section \vref{sec:esbi-openshift} will discuss the implemented Openshift resources, which are used to define and manage the Openshift Project.
\\ \\
Is is assumed, that the reader is familiar with Java Enterprise Development, Maven and microservices. The implemented prototype is available on Github \footnote{https://github.com/cchet-thesis-msc/prototype}. The repository contains a README file, which describes how to setup the prototype. 

\section{Microservice Technologies}
\label{sec:esbi-technolody-fis}
The following sections will give a brief introduction about the most important technologies used to implement the integration services. Each implemented service uses the same technologies and is build the same way, because no matter what the concrete purpose of the service is, they all have to be integrated and run the same way on a Openshift Cluster.

\subsection{JBoss Fuse Integration Services 2.0}
\label{sec:esbi-technology-fis}
JBoss Fuse Integration Services 2.0 is a set of tooling for developing integration services running on a Openshift Cluster. It provides Openshift integrations for different frameworks such as Spring Boot, Karaf or Camel. The services are started via an Java-Agent such as Prometheus or Jolokia, which are used to monitor the service during runtime. Additionally to provided Openshift resources, a Maven Plugin is provided, which allows to interact with the Openshift Cluster during a Maven build. JBoss Fuse Integration Services 2.0 allows developers to interact with a Openshift Cluster in a way like developers did before with an application server \cite{Prometheus2018, Jolokia2018}.

\subsection{Wildfly Swarm}
\label{sec:esbi-technology-swarm}
Wildly Swarm is the JEE answer to Spring Boot, and is a framework, which allows to package an application into an Uber-JAR. An Uber-JAR is a packaged standalone application, which can be started with the command \inlineJava{java -jar}. During the packaging, only those components of an application server are packaged, which are referenced and needed by the application. The application can then be started via \inlineBash{java -jar app.jar}, whereby the application server is bootstrapped programmatically.  The application deployment artifact is a JAVA Web-Archive, which could be hosted in any application server environment, which provides all of the referenced dependencies \cite{WildflySwarm2018}. 

\subsection{Fabric8}
\label{sec:esbi-technology-f8}
Fabric8 is an integrated development platform for developing applications on Kubernetes. Fabric8 provides the Maven Plugin for the JBoss Fuse Integration Services 2.0, and focuses on building Docker Images, managing Kubernetes or Openshift resources and deploying Java applications on Kubernetes or Openshift Clusters \cite{Fabric82018}.
\\ \\
The next Section will discuss the implementations of the microservice aspects discussed in Section \vref{sec:esboc-aspects}.

\section{Security}
\label{sec:esbi-security}
The integration services are secured with OAuth, and authenticate their clients via Keycloak. Keycloak is used as the authentication service, and is a very popular open source identity and authentication application. Wildfly Swarm provides an integration into Keycloak via the Keycloak-Adapter, which only needs to be added as a dependency to the Maven POM and to be configured.

\subsection{Service}
\label{sec:esbi-security-service}
This section will discuss the implementation of the security in the service implementations. Listing \vref{ls:esboi-security-pom} shows the dependency, which brings in the Keycloak Adapter, integrates itself into the Java Web-Security mechanisms, and can therefore be configured with Java Web-Security security constraints.
\begin{listing}
	\xmlFile{\sourceDir/maven-keycloak-swarm.xml}
	\caption{Wildfly Swarm Keycloak dependency in pom.xml}
	\label{ls:esboi-security-pom}
\end{listing}

Listing \vref{ls:esboi-security-yaml} shows an excerpt of the Wildfly Swarm configuration file project-stages.yml, which configures the security constraints for the REST-Endpoint.

\begin{listing}
	\yamlFile{\sourceDir/project-stages-security.yml}
	\caption{Security configuration in project-stages.yml}
	\label{ls:esboi-security-yaml}
\end{listing}

The following two listings are excerpts of the deployment.yml Openshift Template, which is managed in the service code base. Listing \vref{ls:esboi-security-oc-deployment-volume-secret} shows the specification of the secret injection into a Docker Volume. The secrets are injected as files, whereby the file name represents the secret key and the file content represents the secret value. Therefore, that the secrets are managed externally, the developers need to provide the secret name for the service deployment configuration. In this case an expression is used, which can be replaced by Maven Properties, whereby the Maven Properties can be provided in the pom.xml or provided/overwritten by Java Options, during the build process.

\begin{listing}
	\yamlFile{\sourceDir/deployment-volume-secret.yml}
	\caption{Configuration of the secret injection}
	\label{ls:esboi-security-oc-deployment-volume-secret}
\end{listing}

Listing \vref{ls:esboi-security-oc-deployment-volume-mount} show the specification of the mount of the Docker Volume, which provides the secrets. The mount path is also represented by a Maven Property, because this path is also used in the project-stages.yml file, where it points to the service configuration source for the productive stage. The secrets consumed by the services are used the same way as non-sensitive configurations, which are discussed in Section \vref{sec:esbi-configuration}.

\begin{listing}
	\yamlFile{\sourceDir/deployment-volume-secret-container.yml}
	\caption{Configuration volume mount}
	\label{ls:esboi-security-oc-deployment-volume-mount}
\end{listing}

\subsection{Openshift}
\label{sec:esbi-security-openshift}
This section will discuss the Openshift implementation, whereby the implementation is represented by a shell script, which manages the secrets. The secrets are managed outside the code bases of the integration services.
\\ \\
Listing \vref{ls:esboi-security-oc-secret} shows the Openshift CLI-Commands, which are used to create the secrets. The first command creates a secret from literal values which is used by a client service to retrieve authentication tokens. The second command creates a secret from a file, whereby the filename is the secret key and the content is the secret value, which is used by the Keycloak Adapter to validate authentication tokens provided by the clients. 

\begin{listing}
	\bashFile{\sourceDir/bash-oc-secret.txt}
	\caption{Openshift CLI command for creating the secret}
	\label{ls:esboi-security-oc-secret}
\end{listing}

The discussed implementations are the necessary implementations on the Service and Openshift side, to secure services hosted on a Openshift Cluster. No infrastructure code is necessary, only configuration. The following section will discuss the configuration of the integration services, which can be applied to the security as well, because secrets in Openshift are used in the service implementations the same way as configuration parameters.

\section{Configuration}
\label{sec:esbi-configuration}
The integration services use the MicroProfile Config specification to be configurable for multiple stages by exposing all necessary configuration parameters and to be able to consume configuration parameters from different configuration sources via injection. Developers are bound to the configuration or secret name, keys and their value type, but developers are not bound to the configuration or secret source, which allows to provide configurations from different sources and for different stages. 

\subsection{Service}
\label{sec:esbi-config-service}
This section will discuss the implementation of the configuration definition and usage. Listing \vref{ls:esboi-config-pom} shows the dependency, which brings in the MicroProfile Config specification to enable injectable configurations.
 
\begin{listing}
	\xmlFile{\sourceDir/maven-microprofile-config.xml}
	\caption{Wildfly Swarm MicroProfile-Config dependency in pom.xml}
	\label{ls:esboi-config-pom}
\end{listing}

Listing \vref{ls:esboi-config-project-stages-dev} shows the definition of the configuration source with the name \mentionedtext{app.secrets} for the development stage, whereby the configuration properties are provided hard coded.

\begin{listing}
	\bashFile{\sourceDir/project-stages-micro-config-dev.yml}
	\caption{Hard coded configuration for development stage}
	\label{ls:esboi-config-project-stages-dev}
\end{listing}

Listing \vref{ls:esboi-config-project-stages-prod} shows the definition of the configuration source with the name \mentionedtext{app.secrets} for the production stage, whereby the configurations are loaded via a directory. The directory location is represented by an Maven Property, because its used in multiple configuration files, as already discussed in Section \vref{sec:esbi-security-service}. The MicroProfile Config specification will load files in this directory by using the filename as the key and the content as the value.

\begin{listing}
	\yamlFile{\sourceDir/project-stages-micro-config-prod.yml}
	\caption{External configuration for production stage}
	\label{ls:esboi-config-project-stages-prod}
\end{listing}

Listing \vref{ls:esboi-config-inject} shows the injection of the Keycloak Secrets into a CDI Bean, whereby the actual configuration source, the configurations are retrieved from, is unknown. The injected configuration properties are retrieved from a Openshift Secret, but are used in source code the same way as configurations. The Keycloak Secrets are used to retrieve authentication tokens for the REST calls. 

\begin{listing}
	\javaFile{\sourceDir/java-config-inject.java}
	\caption{Injection of Keycloak configuration parameters}
	\label{ls:esboi-config-inject}
\end{listing}

\subsection{Openshift}
\label{sec:esbi-config-openshift}
The Openshift implementation has already been covered by Section \vref{sec:esbi-security-openshift}, because configurations and secrets are injected into Docker Containers the same way, and the configuration shown in this section are actual retrieved from a Openshift Secret. 

\section{Tracing}
\label{sec:esbi-tracing}
The integration services use the MicroProfile OpenTracing specification to provide tracing data to a central tracing service. Jaeger\footnote{https://www.jaegertracing.io/} is used as the tracing service, which collects all tracing data and provides a GUI for analyzing traces. 

\subsection{Service}
\label{sec:esbi-tracing-service}
This section will discuss the implementation of the service tracing. Listing \vref{ls:esboi-tracing-pom} shows the dependency, which brings in the MicroProfile OpenTracing specification to enable tracing. 

\begin{listing}
	\xmlFile{\sourceDir/maven-microprofile-opentracing.xml}
	\caption{Wildfly Swarm MicroProfile-OpenTracing dependency in pom.xml}
	\label{ls:esboi-tracing-pom}
\end{listing}

Listing \vref{ls:esboi-tracing-project-stages} shows the configuration for the integration into an external tracing service, whereby the configuration parameters are provided by Maven Properties, environment variables and constants. The configuration properties are created as System Properties by Wildfly Swarm, whereby  expressions like \mentionedtext{\$\{env.JAEGER\_PORT\}} are resolved during startup.

\begin{listing}
	\yamlFile{\sourceDir/project-stages-opentracing.yml}
	\caption{Configuration for integration into tracing service}
	\label{ls:esboi-tracing-project-stages}
\end{listing}

Listing \vref{ls:esboi-tracing-java} shows a class which is annotated with \inlineJava{@Traced} on class level, which enables tracing for all methods within this class. The annotation \inlineJava{@Traced} enables an interceptor, which implements the tracing logic. 

\begin{listing}
	\javaFile{\sourceDir/java-tracing.java}
	\caption{Enable tracing for a class}
	\label{ls:esboi-tracing-java}
\end{listing}

A trace is a set of so called spans, whereby a span represents one call in a call chain and contains meta-data of the call such as call duration. The interceptor creates a new span for each call and appends the created span to an existing parent span, or the created span is the parent span. 

\subsection{Openshift}
\label{sec:esbi-tracing-openshift}
The communication between the integration services and tracing service is done via UDP protocol, and therefore Openshift does need any special configuration.

\section{Logging}
\label{sec:esbi-logging}
The integration services provide logging to a central log aggregation service. Graylog\footnote{https://www.graylog.org/} is used as the log aggregation service, which collects all logging data and provides a GUI for analyzing logs.
\newpage

\subsection{Service}
\label{sec:esbi-logging-service}
This section will discuss the implementation of the service logging. Listing \vref{ls:esboi-logging-pom} shows the dependencies, which bring in the logging implementations. SLF4J\footnote{https://www.slf4j.org/} has been chosen as the logging facade, whereby an integration in Wildfly Swarm used JBoss Logging is provided by SLF4J.

\begin{listing}
	\xmlFile{\sourceDir/maven-swarm-logging.xml}
	\caption{Wildfly Swarm logging dependencies in pom.xml}
	\label{ls:esboi-logging-pom}
\end{listing}

The following listings are part of the project-stages.yml configuration file and configure logging for different stages. Listing \vref{ls:esboi-logging-format-project-stages} shows the configuration of the logging format, which uses Mapped Diagnostic Context (MDC) parameters to mark a log entry with the transaction id. The configured formatter is used over all stages.

\begin{listing}
	\yamlFile{\sourceDir/project-stages-logging-format.yml}
	\caption{Configuration of the logging format}
	\label{ls:esboi-logging-format-project-stages}
\end{listing}

Listing \vref{ls:esboi-logging-dev-project-stages} shows the logging configuration for the development stage.

\begin{listing}
	\yamlFile{\sourceDir/project-stages-logging-dev.yml}
	\caption{Configuration of the logging for development stage}
	\label{ls:esboi-logging-dev-project-stages}
\end{listing}

Listing \vref{ls:esboi-logging-prod-project-stages} shows the configuration of the logging for the production stage, where the service is contributing its logs to a central log aggregation service. A Syslog logging handler is configured, which sends the logs to the log aggregation service via the SYSLOG\footnote{https://tools.ietf.org/html/rfc5424} protocol.

\begin{listing}
	\yamlFile{\sourceDir/project-stages-logging-prod.yml}
	\caption{Configuration of the logging for production stage}
	\label{ls:esboi-logging-prod-project-stages}
\end{listing}

Listing \vref{ls:esboi-logging-java-transaction-id} shows the implementation of the interface \mentionedtext{ContainerRequestFilter}, which is used to caputre the trace transaction id on a REST Endpoint. The implementation is depending on the Uber MicroProfile OpenTracing specification, because the specification does not provide an transaction id yet.

\begin{listing}
	\javaFile{\sourceDir/java-logging-tracing-id.java}
	\caption{Capture of tracing id on REST Endpoint}
	\label{ls:esboi-logging-java-transaction-id}
\end{listing} 

Listing \vref{ls:esboi-logging-java-producer} shows the CDI Producer for the logger instance. The logger is produced for the Dependent Scope, which means that the life cycle of the logger is managed by the object, which gets the logger injected.

\begin{listing}
	\javaFile{\sourceDir/java-logging-producer.java}
	\caption{CDI Producer for loggers}
	\label{ls:esboi-logging-java-producer}
\end{listing} 

Listing \vref{ls:esboi-logging-java} shows a class using a injected logger to log a info message. As this examples illustrates, the user codes has no knowledge about a log aggregation back-end, and uses the logger as usual.

\begin{listing}
	\javaFile{\sourceDir/java-logging.java}
	\caption{Logger usage}
	\label{ls:esboi-logging-java}
\end{listing} 

\subsection{Openshift}
\label{sec:esbi-logging-openshift}
The integration services send their logs to a central log aggregation service via the UDP protocol, and therefore there are no special settings for Openshift necessary. Nevertheless, logs send to the console are logged by Openshift and can be seen in the Openshift Web-Console.

\section{Fault Tolerance}
\label{sec:esbi-fault}
The integration services use the MicroProfile FaultTolerance specification to define fault tolerance behavior on methods. As implementation for the MicroProfile FaultTolerance specification  Hystrix\footnote{https://github.com/Netflix/Hystrix/wiki/How-it-Works} is used, which has been contributed to the open source community by Netflix.

\subsection{Service}
\label{sec:esbi-fault-service}
The integration services use the MicroProfile Fault-Tolerance specification to define the service fault tolerance behavior, which defines the service resilience. The following Listing \vref{ls:esboi-fault-tolerance-java} is one example of how to use the MicroProfile Fault-Tolerance specification.

\begin{listing}
	\xmlFile{\sourceDir/maven-microprofile-fault-tolerance.xml}
	\caption{Wildfly Swarm fault tolerance dependencies in pom.xml}
	\label{ls:esboi-fault-tolerance-pom}
\end{listing}

Listing \vref{ls:esboi-fault-tolerance-java} shows the CDI Producer method for producing the Keycloak token, which defines fault behavior for this method. The special use of the method as a CDI Producer method does not affect the fault tolerance logic. Each time when the producer method is called a token request is send to the Keycloak, to retrieve a access token. The invocation is retried 5 times with a 100 millisecond delay, and each invocation is timed out after 5 seconds.

\begin{listing}
	\javaFile{\sourceDir/java-fault-tolerance.java}
	\caption{Fault tolerance definition on CDI Producer method}
	\label{ls:esboi-fault-tolerance-java}
\end{listing} 

\subsection{Openshift}
\label{sec:esbi-fault-openshift}
The fault tolerance behavior as discussed in Section \vref{sec:esbi-fault-service} only affects the service itself and not Openshift. But, Openshift provides a kind of fault tolerance by for instance restarting a Pod which has crashed.
\newpage 

\section{REST-API Management}
\label{sec:esbi-api}
The integration services use Swagger\footnote{https://swagger.io/} to provide documentation for their REST-API. Swagger provides an intermediate format which can be used by tooling for testing and client generation. The REST-API represents the public view of the service, which is implemented in a way, so that it is de-coupled from the Service-API, and supports several ways to perform API migrations.
\\ \\
The following sections will discuss the implementation of the REST-API management on the service side and the REST-API usage on the client side. Both use Swagger, whereby the service provides Swagger documentation and the client uses the Swagger documentation to generate REST-Clients.

\subsection{Service}
\label{sec:esbi-api-service}
This section will discuss the implementation of the service REST-API implementation and management. Listing \vref{ls:esboi-api-service-pom} shows the dependency, which brings in the Swagger specification and implementation for an service which provides Swagger Documentation.

\begin{listing}[h]
	\xmlFile{\sourceDir/maven-swagger-service.xml}
	\caption{Wildfly Swarm Swagger dependency in pom.xml for the service}
	\label{ls:esboi-api-service-pom}
\end{listing}

Listing \vref{ls:esboi-api-swagger-conf} shows the \mentionedtext{swarm.swagger.conf} configuration file, which configures Swagger for the documented service. Swagger will scan the configured packages for interfaces and classes, which provide Swagger Documentations, and during startup, Swagger will generate a \mentionedtext{swagger.json} files, which contains the Swagger specification of the REST-API documentation.   

\begin{listing}[h]
	\yamlFile{\sourceDir/swarm.swagger.conf}
	\caption{Swagger configuration}
	\label{ls:esboi-api-swagger-conf}
\end{listing}

Listing \vref{ls:esboi-api-swagger-java} shows an interface, which is specifies an REST-Endpoint via JAX-RS Annotations, and provides Swagger documentation with Swagger annotations. Additionally, Java Bean-Validation annotations are used to define constraints for the input arguments of the REST operations, so that implicit validation is applied on all incoming requests. The JAX-RS, Java Bean-Validation and Swagger annotations are scanned and applied to the generated Swagger specification.

\begin{listing}[h]
	\javaFile{\sourceDir/java-swagger.java}
	\caption{Swagger documented REST-Interface}
	\label{ls:esboi-api-swagger-java}
\end{listing} 

\subsection{Client}
\label{sec:esbi-api-client}
This section will discuss the implementation of the client, which uses the \mentionedtext{swagger.json} file for generating the REST-Client. Listing \vref{ls:esboi-api-client-add-sources-pom} shows the configuration of the Maven Helper-Plugin, which is use to add the generated sources for the compilation.

\begin{listing}[h]
	\xmlFile{\sourceDir/maven-swagger-client-add-sources.xml}
	\caption{Maven Helper-Plugin configuration in pom.xml}
	\label{ls:esboi-api-client-add-sources-pom}
\end{listing}
\ \newpage

Listing \vref{ls:esboi-api-client-swagger-plugin-pom} shows the Swagger Maven-Plugin configuration in the client \mentionedtext{pom.xml}, which is used to generate the REST-Client for the client during Maven Build. Custom Swagger Code-Generator templates are used, due to the fact that there is no Swagger Code-Generator, which only generates plain JAX-RS interfaces. 

\begin{listing}[h]
	\xmlFile{\sourceDir/maven-swagger-client-swagger-plugin.xml}
	\caption{Swagger Maven-Plugin configuration in pom.xml}
	\label{ls:esboi-api-client-swagger-plugin-pom}
\end{listing}

Listing \vref{ls:esboi-api-client-clean-pom} shows the configuration of the Maven Clean-Plugin, which is used to clean the unwanted resources. The swagger Maven-Plugin generates additional resources, which cannot be turned off, therefore the Maven Clean-Plugin is used to clean the generated sources from unwanted generated resources. 

\begin{listing}[h]
	\xmlFile{\sourceDir/maven-swagger-client-clean.xml}
	\caption{Maven Clean-Plugin configuration in pom.xml}
	\label{ls:esboi-api-client-clean-pom}
\end{listing}

Listing \vref{ls:esboi-api-client-api-java} shows the generated JAX-RS interface, which is generated by using the Swagger documentation. The method name is the REST-API operation name and the defined constraints provided by the Java Bean-Validation annotations have been added to the generated Swagger documentation. 

\begin{listing}[h]
	\javaFile{\sourceDir/java-swagger-client.java}
	\caption{Maven Clean-Plugin configuration in pom.xml}
	\label{ls:esboi-api-client-api-java}
\end{listing}

Listing \vref{ls:esboi-api-client-api-builder-java} shows how to build an REST-Client for the generated JAX-RS interfaces, whereby the developer an work with the generated API and the logic for handling the request and response is provided by RESTEasy\footnote{https://resteasy.github.io/}. Thus, changes made to the REST-API will cause compile errors, therefore the usage of the REST-Client is type safe. The MicroProfile OpenTracing specification provides a JAX-RS client filter, which integrates the REST-Client request into the configured service tracing. This integration ensures that all calls in the service are part of the current trace.

\begin{listing}[h]
	\javaFile{\sourceDir/java-swagger-client-builder.java}
	\caption{Example of building a type safe REST-Client}
	\label{ls:esboi-api-client-api-builder-java}
\end{listing}

In the prototype, the built REST-Clients are provided as CDI Beans to the consuming services, whereby the Rest-Clients are managed by a custom proxy to apply proper fault tolerance behavior to the REST-Client method calls.

\subsection{Openshift}
\label{sec:esbi-api-openshift}
The REST-API management and migration does not affect Openshift, because the services REST-API is either accessible only within the Openshift Project network, or is exposed via a single Openshift Route. For an exposed service, additional Openshift Routes could be created, which for instance redirect calls made to an REST-API version to another REST-API version. 

\section{Openshift Project}
\label{sec:esbi-openshift}
This section will discuss the implementation of the Openshift Project, which represents the ESB. The implementations are represented by scripts, configurations and secrets, which ensure that the Openshift Project is properly setup and provides all resources consumed by the services, such as Openshift Volumes, Openshift ConfigMaps and Openshift Secrets. Each service hosted on the Openshift Project provides and script for managing the resources referenced by the services. 
\\ \\
The scripts, configurations and secrets are managed by operators, which ensure that the Openshift Projects are properly setup and provide all configurations and secrets for the specific stage the Openshift Project represents.

\subsection{Scripts}
\label{sec:esbi-openshift-secrets}
This section will discuss the implemented scripts for managing the Openshift resources consumed by the services. Listing \vref{ls:esboi-openshift-oc-service} shows an excerpt of an implemented script, which manages Openshift Secrets created from files for a service. The Openshift Secrets could also have been created from Openshift Templates, whereby the secrets are either hard-coded in the Openshift Templates or are provided via Openshift Template-Parameter.

\begin{listing}[h]
	\bashFile{\sourceDir/bash-oc-service.sh}
	\caption{Shell functions for managing Openshift Secrets via a CLI}
	\label{ls:esboi-openshift-oc-service}
\end{listing}

The scripts are a convenient way for managing Openshift Secrets, and are more flexible then template based Openshift Secret management, which also would require scripts for creation and deletion of the by Openshift Templates created Openshift resources. The scripts are separated from the actual secrets or configurations, and can therefore be used for all stages, whereby each stage provides their secrets and configurations. 

\subsection{Templates}
\label{sec:esbi-openshift-config}
Because of the usage of Fuse Integration Services 2.0 and Fabric8, which provide all necessary resources for managing integration services in Openshift, no Openshift Templates had to be implemented. The Openshift Templates such as \mentionedtext{deployment.yml} of the integration services are managed in the code bases of the integration services, and are applied via the Fabric8 Maven-Plugin.



