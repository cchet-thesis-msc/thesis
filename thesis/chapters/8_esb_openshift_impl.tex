\chapter{Implementation ESB in Openshift}
\label{cha:esbi}
This chapter will discuss the implemented prototype, which has been designed in Chapter \vref{cha:esboc}. The implemented prototype uses lots of Java Enterprise Frameworks and Java Enterprise-Platform specifications, which are beyond the scope of this thesis, therefore a focus will be set on the implementations of the aspects discussed in Section \vref{sec:esboc-aspects}. Is is assumed, that the reader is familiar with Java Enterprise Development, Java Enterprise Frameworks, Maven and the microservices architecture. The implemented prototype is available on Github \footnote{https://github.com/cchet-thesis-msc/prototype}. The repository contains a \mentionedtext{README.adoc} file, which describes how to setup the prototype on a Windows Host. \\

The services are implemented as microservices, with their own life-cycle, and run as standalone applications in Docker Containers on the Openshift Cluster. The services communicate via REST with each other, whereby each service provides a proper managed public API and documentation. The code bases of the services are managed separately, which completely decouples the services from each other. \\

As the prototype illustrates, the ESB is represented by an Openshift Project on an Openshift Cluster, whereby the Openshift Cluster acts as the platform for the hosted services. The services will be hosted in an Openshift Project, whereby the Openshift Project provides features as discussed in Section \vref{sec:paas-openshift-project} for managing the life-cycle of the hosted services. The implemented resources for managing the Openshift Project are discussed in Section \vref{sec:esbi-openshift}. \\

The following Section will briefly introduce the technologies and frameworks, which were used for implementing the services, which are running on the Openshift Cluster.

\section{Microservice Technologies}
\label{sec:esbi-technolody-fis}
The following sections will give a brief introduction about the most important technologies and frameworks, used to implement the services as microservices. Each implemented service is setup the same way, because the concrete purpose of the service doesn't matter, when the microservices have to be integrated into a distributed service network. All of the following technologies and frameworks provide all necessary API, implementations, and tooling, for implementing a microservice with the Java Enterprise-Platform, which is hosted on an Openshift Cluster.

\subsection{JBoss Fuse Integration Services 2.0}
\label{sec:esbi-technology-fis}
JBoss Fuse Integration Services 2.0 is a set of tooling for developing services running on an Openshift Cluster. It provides Openshift integrations for different frameworks such as Spring Boot, Karaf or Camel. The services are started via an Java Agent such as Prometheus or Jolokia, which are used to monitor the services during runtime. Additionally, a Maven Plugin is provided, which allows to interact with the Openshift Cluster during a Maven build, whereby the service life-cycle on an Openshift Cluster can be managed via Maven Goals. JBoss Fuse Integration Services 2.0 allows developers to interact with an Openshift Cluster in a way like developers did before with an application server like Wildfly\cite{Prometheus2018, Jolokia2018}.

\subsection{Thorntail.io}
\label{sec:esbi-technology-swarm}
Thorntail.io, previously called Wildfly Swarm, is the Java Enterprise answer to Spring Boot, and is a framework based on Wildfly, which allows to package an application into an Uber-JAR. An Uber-JAR is a packaged standalone application, which can be started with the command \inlineJava{java -jar}. During the packaging, only those components of Wildfly are packaged, which are referenced and needed by the application. The application can then be started via \inlineBash{java -jar app.jar}, whereby the application server is bootstrapped programmatically. The Uber-Jar is a repackaged Java Web-Archive, which could be hosted on any Java application platform, which provides all of the referenced dependencies, which are added during the repackaging\cite{WildflySwarm2018,Wildfly2017}.  \\

During the implementation of the prototype, Wildfly Swarm has been renamed to Thorntail.io, whereby the Maven Group-Id has been renamed from \mentionedtext{org.wildfly.swarm} to \mentionedtext{io.thorntail}. The Maven Dependencies are still the same, but with a different Maven Group-Id.

\subsection{Fabric8}
\label{sec:esbi-technology-f8}
Fabric8 is an integrated development platform for developing applications on Kubernetes. Fabric8 provides a  Maven Plugin for the JBoss Fuse Integration Services 2.0, and focuses on building Docker Images, managing Kubernetes or Openshift resources, and deploying Java applications on Kubernetes or Openshift clusters. With the Maven Plugin, the interaction of developers with Openshift is reduced to a minimum, for instance, no custom Openshift BuildConfig has to be provided, because it is generated by the Maven Plugin itself\cite{Fabric82018}. \\

The following sections will discuss the implementations of the microservice aspects as discussed in Section \vref{sec:esboc-aspects}.

\section{Security}
\label{sec:esbi-security}
The services are secured with OAuth2, and authenticate their clients via Keycloak. Keycloak is used as the authentication service, and is a very popular open source identity and authentication application. Thorntail.io provides an integration into Keycloak via the Keycloak Adapter, which needs to be added as a dependency to the Maven \mentionedtext{pom.xml}. The adapter needs a configuration, to know what resources are secured.

\subsection{Service}
\label{sec:esbi-security-service}
This section will discuss the implementation of the security in the service implementations. Listing \vref{ls:esboi-security-pom} shows the dependency, which brings in the Keycloak Adapter. The Keycloak Adapter integrates itself into the Java Web-Security mechanisms, and can therefore be configured with Java Web-Security security constraints.

\begin{listing}[h]
	\xmlFile{\sourceDir/maven-keycloak-swarm.xml}
	\caption{Keycloak Adapter dependency in pom.xml}
	\label{ls:esboi-security-pom}
\end{listing}

Listing \vref{ls:esboi-security-yaml} shows an excerpt of the Thorntail.io configuration file \mentionedtext{project-stages.yml}, which configures the security constraints for the REST Endpoints.

\begin{listing}[h]
	\yamlFile{\sourceDir/project-stages-security.yml}
	\caption{Security configuration in project-stages.yml}
	\label{ls:esboi-security-yaml}
\end{listing}

The following two listings are excerpts of the \mentionedtext{deployment.yml} Openshift Template, which is managed in the service code base. Listing \vref{ls:esboi-security-oc-deployment-volume-secret} shows the specification of the secret injection into a Docker Volume. The secrets are injected as files, whereby the file name represents the secret key and the file content represents the secret value. Therefore, that the secrets are managed externally, the developers need to provide the secret name for the service deployment configuration. In this case an expression is used, which references a Maven Property, whereby the Maven Property can be provided in the \mentionedtext{pom.xml} or provided/overwritten by Java Options during the Maven Build.
\newpage

\begin{listing}[h]
	\yamlFile{\sourceDir/deployment-volume-secret.yml}
	\caption{Secret injection configuration in deployment.yml}
	\label{ls:esboi-security-oc-deployment-volume-secret}
\end{listing}

Listing \vref{ls:esboi-security-oc-deployment-volume-mount} shows the specification of the mount of the Docker Volume, which provides the secrets for the application. The mount path is also represented by a Maven Property, because this path is also used in the \mentionedtext{project-stages.yml} file, where it points to the service configuration source for the production stage. The secrets consumed by the services are used the same way as non-sensitive configurations, which are discussed in Section \vref{sec:esbi-configuration}.

\begin{listing}[h]
	\yamlFile{\sourceDir/deployment-volume-secret-container.yml}
	\caption{Secret volume mount configuration in deployment.yml}
	\label{ls:esboi-security-oc-deployment-volume-mount}
\end{listing}

\subsection{Openshift}
\label{sec:esbi-security-openshift}
This section will discuss the Openshift implementation, whereby the implementation is represented by a shell script, which manages the Openshift Secrets. The secrets are managed outside the code bases of the services, and are supposed to be maintained by operators.

\begin{listing}[h]
	\bashFile{\sourceDir/bash-oc-secret.txt}
	\caption{Openshift CLI commands for creating secrets}
	\label{ls:esboi-security-oc-secret}
\end{listing}
	
Listing \vref{ls:esboi-security-oc-secret} shows the Openshift CLI-Commands, which are used to create the Openshift Secrets. The first command creates an Openshift Secret from literal values, which provides the configurations for the service. The second command creates an Openshift Secret from a file, whereby the filename is the secret key and the file content is the secret value. 
\newpage

This section discussed the implementations, which are necessary to secure services hosted on an Openshift Cluster via OAuth2 with Keycloak. No source code is necessary, only configuration. The following section will discuss the configuration of the services, which can be applied to the security as well, because secrets in Openshift are used in the service implementations, the same way as configuration parameters.

\section{Configuration}
\label{sec:esbi-configuration}
The services use the MicroProfile-Config specification, to be configurable for multiple stages. The services consume the configuration parameters via injection, which can be provided from different configuration sources. Developers are bound to the configuration/secret name, keys, and value type. Developers are not bound to the configuration/secret source, which allows to provide configurations/secrets from different sources, and for different stages. 

\subsection{Service}
\label{sec:esbi-config-service}
This section will discuss the implementation of the configuration definition and usage. Listing \vref{ls:esboi-config-pom} shows the dependency, which brings in the MicroProfile-Config specification and implementation to enable injectable configurations.
 
\begin{listing}[h]
	\xmlFile{\sourceDir/maven-microprofile-config.xml}
	\caption{MicroProfile-Config dependency in pom.xml}
	\label{ls:esboi-config-pom}
\end{listing}

Listing \vref{ls:esboi-config-project-stages-dev} shows the definition of the configuration source in the \mentionedtext{project-stages.yml} for the development stage, whereby the configuration parameter values are provided hard coded.

\begin{listing}[h]
	\bashFile{\sourceDir/project-stages-micro-config-dev.yml}
	\caption{Hard coded configuration for development stage}
	\label{ls:esboi-config-project-stages-dev}
\end{listing}
\ \newpage

Listing \vref{ls:esboi-config-project-stages-prod} shows the definition of the configuration source in the \mentionedtext{project-stages.yml} for the production stage, whereby the configuration parameter values are loaded from files located in the configured directory. The directory location is represented by an expression referencing a Maven Property, because its used in multiple configuration files. The expression will be resolved as discussed in Section \vref{sec:esbi-security-service}.

\begin{listing}[h]
	\yamlFile{\sourceDir/project-stages-micro-config-prod.yml}
	\caption{External configuration for production stage}
	\label{ls:esboi-config-project-stages-prod}
\end{listing}

Listing \vref{ls:esboi-config-inject} shows the injection of the Keycloak Secrets into a CDI Bean, whereby the source of the configurations is not shown. The injected configuration properties are retrieved from an Openshift Secret, but are used in the source code the same way as configurations.

\begin{listing}[h]
	\javaFile{\sourceDir/java-config-inject.java}
	\caption{Injection of Keycloak configuration parameters}
	\label{ls:esboi-config-inject}
\end{listing}

\subsection{Openshift}
\label{sec:esbi-config-openshift}
The Openshift implementation has already been covered by Section \vref{sec:esbi-security-openshift}, because all of the configurations are managed as Openshift Secrets, because they contain sensitive data. 

\section{Tracing}
\label{sec:esbi-tracing}
The services use the MicroProfile-OpenTracing specification to provide tracing data to a central tracing service. Jaeger is used as the tracing service, which collects all tracing data and provides a GUI for analyzing the collected traces\cite{CNCFJaeger2018}. 

\subsection{Service}
\label{sec:esbi-tracing-service}
This section will discuss the implementation of the service tracing. Listing \vref{ls:esboi-tracing-pom} shows the dependency, which brings in the MicroProfile-OpenTracing specification and implementation to enable tracing. 

\begin{listing}[h]
	\xmlFile{\sourceDir/maven-microprofile-opentracing.xml}
	\caption{MicroProfile-OpenTracing dependency in pom.xml}
	\label{ls:esboi-tracing-pom}
\end{listing}

Listing \vref{ls:esboi-tracing-project-stages} shows the configuration  in the \mentionedtext{project-stages.yml}, for the integration into the Jaeger tracing service, whereby the configuration parameters are provided by Maven Properties, environment variables and literals. The System Property JAEGER\_ENDPOINT defines the HTTP collector endpoint of the Jaeger tracing service, and is provided via an environment variable, which gets injected from an Openshift ConfigMap.

\begin{listing}[h]
	\yamlFile{\sourceDir/project-stages-opentracing.yml}
	\caption{Configuration of Jaeger integration in project-stages.yml}
	\label{ls:esboi-tracing-project-stages}
\end{listing}

Listing \vref{ls:esboi-tracing-java} shows a class which is annotated with \inlineJava{@Traced} on class level, which enables tracing for all methods within this class. The annotation \inlineJava{@Traced} enables a CDI Interceptor, which implements the tracing logic. \\

\begin{listing}[h]
	\javaFile{\sourceDir/java-tracing.java}
	\caption{Traced CDI Bean}
	\label{ls:esboi-tracing-java}
\end{listing}
\ \newpage

A trace is a set of so called spans, whereby a span represents one call in a call chain and contains meta-data of the call, such as the call duration. The CDI Interceptor creates a new span for each method invocation, and appends the created span to an existing parent span, or the created span is the parent span. 

\subsection{Openshift}
\label{sec:esbi-tracing-openshift}
The communication between the services and the tracing service is performed via HTTP, therefore Openshift does need any special configuration. Openshift doesn't interfere with outgoing connections, only incoming.

\section{Logging}
\label{sec:esbi-logging}
The services provide logging to a central log aggregation service. Graylog is used as the log aggregation service, which collects all logging data and provides a GUI for analyzing the aggregated logs\cite{Graylog2018}.

\subsection{Service}
\label{sec:esbi-logging-service}
This section will discuss the implementation of the service logging. Listing \vref{ls:esboi-logging-pom} shows the dependency, which brings in the Thorntail.io logging implementation, which needs to be configured to know how and where to send the produced logs.

\begin{listing}[h]
	\xmlFile{\sourceDir/maven-swarm-logging.xml}
	\caption{Logging dependency in pom.xml}
	\label{ls:esboi-logging-pom}
\end{listing}

The provided logging implementation of Thorntail.io does not support the used Graylog service, therefore the library logstash-gelf was added, which supports Graylog and provides a Wildfly compatible log handler, which can be used with Thorntail.io. The library is integrated via a custom JBoss Module, because it is only needed during runtime. The module.xml for the JBoss Module for logstash-gelf was defined at src/main/resources/modules/<module\_name>/main/module.xml. Listing \vref{ls:esboi-logging-logstash} shows the custom JBoss Module \mentionedtext{module.xml}, which integrates the logstash-gelf library. The defined artifacts are downloaded by Thorntail.io during the re-packaging phase of the Maven Build\cite{LogstashGelf2018}.
\newpage

\begin{listing}[h]
	\xmlFile{\sourceDir/paluch-module.xml}
	\caption{JBoss module.xml for integrating logstash-gelf}
	\label{ls:esboi-logging-logstash}
\end{listing}

The following listings are part of the \mentionedtext{project-stages.yml}, and configure the logging for the different stages. Listing \vref{ls:esboi-logging-format-project-stages} shows the configuration of the logging format, which uses Mapped-Diagnostic-Context (MDC) parameters to mark a log entry with the transaction id, provided by the tracing implementation. The configured formatter is defined globally, therefore it will used for all stages.

\begin{listing}[h]
	\yamlFile{\sourceDir/project-stages-logging-format.yml}
	\caption{Logging format configuration in project-stages.yml}
	\label{ls:esboi-logging-format-project-stages}
\end{listing}

Listing \vref{ls:esboi-logging-dev-project-stages} shows the logging configuration for the development stage.

\begin{listing}[h]
	\yamlFile{\sourceDir/project-stages-logging-dev.yml}
	\caption{Logging configuration for development stage in project-stages.yml}
	\label{ls:esboi-logging-dev-project-stages}
\end{listing}

Listing \vref{ls:esboi-logging-prod-project-stages} shows the configuration in the \mentionedtext{project-stages.yml} for the logging of the production stage, whereby logs are send to a central log aggregation service. A log handler of the logstash-gelf library is configured, which sends the logs to the log aggregation service via HTTP.

\begin{listing}[h]
	\yamlFile{\sourceDir/project-stages-logging-prod.yml}
	\caption{Logging configuration for production stage in project-stages.yml}
	\label{ls:esboi-logging-prod-project-stages}
\end{listing}

Listing \vref{ls:esboi-logging-java-transaction-id} shows the implementation of the interface \mentionedtext{ContainerRequestFilter} provided by the JAX-RS specification, which is used to capture the current trace transaction id on the REST Endpoints. The implementation is depending on the Uber MicroProfile-OpenTracing implementation, because the specification itself doesn't provide an accessor for the transaction id yet. The captured transaction id is set into MDC, whereby the formatter, defined in Listing \vref{ls:esboi-logging-format-project-stages}, references the MDC parameter. In the production stage, the configured log handler sends the MDC parameters to the log aggregation back-end as own fields.

\begin{listing}[h]
	\javaFile{\sourceDir/java-logging-tracing-id.java}
	\caption{Capture of the tracing id via a JAX-RS Filter}
	\label{ls:esboi-logging-java-transaction-id}
\end{listing} 

Listing \vref{ls:esboi-logging-java-producer} shows the CDI Producer method, which provides the logger instances for injection points. The logger is produced for the Dependent Scope, which means, that the life-cycle of the logger instance is managed by the CDI Bean, which gets the logger injected.

\begin{listing}[h]
	\javaFile{\sourceDir/java-logging-producer.java}
	\caption{CDI Producer for dependent scoped logger instances}
	\label{ls:esboi-logging-java-producer}
\end{listing} 

Listing \vref{ls:esboi-logging-java} shows a class using an injected logger to log a info message. As this examples illustrates, the user code has no knowledge about a log aggregation back-end or about a transaction id.

\begin{listing}[h]
	\javaFile{\sourceDir/java-logging.java}
	\caption{Logger usage in a CDI Bean}
	\label{ls:esboi-logging-java}
\end{listing} 

\subsection{Openshift}
\label{sec:esbi-logging-openshift}
The services send their logs to a central log aggregation service via HTTP, and therefore no special settings for Openshift necessary. Nevertheless, logs send to the console are collected by Openshift and can be analyzed in the Openshift Web-Console as well.

\section{Fault Tolerance}
\label{sec:esbi-fault}
The services use the MicroProfile-FaultTolerance specification to define fault tolerance behavior on methods. Hystrix is a popular framework for failure handling in applications, was the inspiration for the MicroProfile-FaultTolerance specification, and is used as the back-end for the Thorntail.io provided dependency\cite{NetflixHystrix2018}.

\subsection{Service}
\label{sec:esbi-fault-service}
This section will discuss the implementation of the service fault tolerance. The services use the MicroProfile-FaultTolerance specification to define the service fault tolerance behavior, which defines the service resilience. Listing \vref{ls:esboi-fault-tolerance-pom} shows the dependency, which brings in the fault tolerance specification and implementation.

\begin{listing}[h]
	\xmlFile{\sourceDir/maven-microprofile-fault-tolerance.xml}
	\caption{MicroProfile-FaultTolerance dependency in pom.xml}
	\label{ls:esboi-fault-tolerance-pom}
\end{listing}

Listing \vref{ls:esboi-fault-tolerance-java} shows the CDI Producer method for producing the Oauth token, whereby the method defines fault tolerance behavior via annotations. The applied annotations active CDI Interceptors, which implemented the specific fault tolerance logic. The special use of the method as a CDI Producer doesn't affect the fault tolerance logic. Each time when the producer method is called a token request is send to Keycloak to retrieve an access token. The invocation is retried 5 times with a 100 millisecond delay, and each invocation is timed out after 5 seconds.

\begin{listing}[h]
	\javaFile{\sourceDir/java-fault-tolerance.java}
	\caption{Fault tolerance definition on a CDI Producer method}
	\label{ls:esboi-fault-tolerance-java}
\end{listing} 

\subsection{Openshift}
\label{sec:esbi-fault-openshift}
The fault tolerance behavior as discussed in Section \vref{sec:esbi-fault-service} only affects the service itself and not Openshift. But, Openshift provides a kind of fault tolerance, for instance by restarting crashed Pods.

\section{API-Management}
\label{sec:esbi-api}
The services use Swagger to provide documentation for their REST API. Swagger provides an intermediate format, which can be used by tooling for testing and client generation. The REST API represents the public view of the service, which is implemented in a way, so that it is decoupled from the service logic, and supports several ways to perform API migrations. \\

The following sections will discuss the implementation of the REST API-Management on the service side, and the REST API usage on the client side. Both use Swagger, whereby the service provides Swagger Documentation, and the clients are generated by using the service provided Swagger Documentation.

\subsection{Service}
\label{sec:esbi-api-service}
This section will discuss the management and implementation of the service REST API. Listing \vref{ls:esboi-api-service-pom} shows the dependencies, which bring in the 
\begin{itemize}
	\item the Java BeanValidation implementation, 
	\item the JAX-RS Server implementation,
	\item the JAX-RS Server Java-BeanValidation integration,
	\item and the Swagger specification and implementation. 
\end{itemize}

\begin{listing}[h]
	\xmlFile{\sourceDir/maven-swagger-service.xml}
	\caption{JAX-RS/BeanValidation/Swagger dependencies in pom.xml}
	\label{ls:esboi-api-service-pom}
\end{listing}

Listing \vref{ls:esboi-api-swagger-conf} shows an excerpt of the  \mentionedtext{project-stages.yml}, which configures Swagger for the documented service. During startup, Swagger will scan the configured packages for interfaces and classes, which provide documentation in form of Swagger Annotations. The scanned documentations are written to a file named \mentionedtext{swagger.json}, which contains the Swagger Documentation of the service REST API.  
\newpage  

\begin{listing}[h]
	\yamlFile{\sourceDir/project-stages-swagger.yml}
	\caption{Swagger configuration in project-stages.yml}
	\label{ls:esboi-api-swagger-conf}
\end{listing}

Listing \vref{ls:esboi-api-swagger-java} shows an interface, which specifies a REST Endpoint via JAX-RS Annotations, and provides documentation via Swagger Annotations. Additionally, Java BeanValidation-Annotations are used to define constraints for the input arguments of the REST Operations, so that validation is applied on all incoming requests. The JAX-RS, Java BeanValidation, and Swagger Annotations, are scanned and applied to the generated Swagger Documentation.

\begin{listing}[h]
	\javaFile{\sourceDir/java-swagger.java}
	\caption{JAX-RS interface with Swagger Annotations}
	\label{ls:esboi-api-swagger-java}
\end{listing}

\subsection{Client}
\label{sec:esbi-api-client}
This section will discuss the implementation of the REST Client, which is generated by the Swagger Maven-Plugin by using the service provided \mentionedtext{swagger.json} file. The following listings show the configuration of the Maven Plugins, which are used to generate a REST Client from a Swagger Documentation during a Maven Build. \\

Listing \vref{ls:esboi-api-client-add-sources-pom} shows the configuration of the Maven Helper-Plugin in the consumer service \mentionedtext{pom.xml}, which is used to add the generated REST Client sources for the compilation. The source directory points to the directory, where the generated REST Client sources are located.
\newpage

\begin{listing}[h]
	\xmlFile{\sourceDir/maven-swagger-client-add-sources.xml}
	\caption{Maven Helper-Plugin configuration in pom.xml}
	\label{ls:esboi-api-client-add-sources-pom}
\end{listing}

Listing \vref{ls:esboi-api-client-clean-pom} shows the configuration of the Maven Clean-Plugin in the consumer service \mentionedtext{pom.xml}, which is used to clean the unwanted generated sources and resources. The Swagger Maven-Plugin generates a standalone REST Client, which cannot be turned off, but only the plain generated models and interfaces are needed. 

\begin{listing}[h]
	\xmlFile{\sourceDir/maven-swagger-client-clean.xml}
	\caption{Maven Clean-Plugin configuration in pom.xml}
	\label{ls:esboi-api-client-clean-pom}
\end{listing}

Listing \vref{ls:esboi-api-client-swagger-plugin-pom} shows the Swagger Maven-Plugin configuration in the consumer service \mentionedtext{pom.xml}, which is used to generate the REST Client during the Maven Build. Custom Swagger Code-Generator templates are used, due to the fact that, there is no Swagger Code-Generator, which only generates plain JAX-RS interfaces and models. 
\newpage

\begin{listing}[h]
	\xmlFile{\sourceDir/maven-swagger-client-swagger-plugin.xml}
	\caption{Swagger Maven-Plugin configuration in pom.xml}
	\label{ls:esboi-api-client-swagger-plugin-pom}
\end{listing}

Listing \vref{ls:esboi-api-client-api-java} shows an excerpt of a generated JAX-RS interface, which was generated from a Swagger Documentation, which was provided by a generated \mentionedtext{swagger.json} file. The generated JAX-RS interface is very similar to the original JAX-RS interface, but could contain differences, for instance when a REST Operation parameter of type string was documented as value type number.

\begin{listing}[h]
	\javaFile{\sourceDir/java-swagger-client.java}
	\caption{Generated JAX-RS interface}
	\label{ls:esboi-api-client-api-java}
\end{listing}

Listing \vref{ls:esboi-api-client-api-builder-java} shows how to build an REST-Client for the generated JAX-RS interfaces, whereby developers work with the generated API, and the logic for handling the request and response is provided by RESTEasy. Changes made to the Swagger Documentation could cause compile errors, because the signature of the generated interface could differ from the previous generated version. Therefore, the usage of the REST Client is type safe. The MicroProfile-OpenTracing implementation provides a JAX-RS Client-Filter, which ensures, that the REST Clients contribute to the tracing. A custom JAX-RS Client-Filter has been implemented, which retrieves the OAuth2 Token from the CDI Container, and sets the token on the HTTP Authentication-Header of the client request\cite{RESTEasy2018}.

\begin{listing}[h]
	\javaFile{\sourceDir/java-swagger-client-builder.java}
	\caption{Building a type safe REST client}
	\label{ls:esboi-api-client-api-builder-java}
\end{listing}

In the prototype, the built REST Clients are injectable into CDI Beans, whereby the Rest Clients are managed by a custom proxy, which applies proper fault tolerance behavior to the REST Client method calls.

\subsection{Openshift}
\label{sec:esbi-api-openshift}
The REST API-Management and migration doesn't affect Openshift, because the services REST API is either accessible only within the Openshift Project network, or is exposed via a single Openshift Route. Openshift doesn't provide any mechanisms for redirecting requests to other services based on path conditions, as for instance Nginx is capable to do so. 

\section{Openshift Project}
\label{sec:esbi-openshift}
This section will discuss the implementation of the Openshift Project, which represents the ESB. The implementations are represented by scripts, configurations and secrets, which ensure that the Openshift Project is properly setup, and provides all resources needed by the services, such as Openshift ConfigMaps and Openshift Secrets. The Openshift resources, which are consumed by the services, are managed by one script per service. The scripts, configurations and secrets are managed by operators, who ensure, that the Openshift Projects are properly setup, and provide all Openshift resources for the services, for a specific stage, an Openshift Project represents.
\newpage

The Openshift related resources of a service, such as the scripts, configurations and secrets, are organized in the following directory structure.
\begin{itemize}
	\item \textbf{/<service\_name>} is the directory holding all service related resources.
	\item \textbf{/<service\_name>/config/<stage>} is the directory holding the service configuration for a specific stage.
\end{itemize}

The stage is defined via the environment variable \mentionedtext{STAGE}, which acts as the selector for the configurations to use as shown in Listing \vref{ls:esboi-openshift-oc-service}.

\subsection{Scripts}
\label{sec:esbi-openshift-secrets}
This section will discuss the implemented scripts for managing a service and its needed Openshift resources in Openshift. Listing \vref{ls:esboi-openshift-oc-service} shows an excerpt of an implemented script for a service, which manages Openshift Secrets, and provides functions for scaling. The creation of secrets has already been discussed in Section \vref{sec:esbi-security-openshift}. The Openshift Secrets could also have been created from Openshift Templates, whereby the secrets are either hard-coded in the Openshift Templates, or are provided via Openshift Template-Parameters. The scaling of the service could also be performed via the Fabric8 Maven-Plugin, but operators usually don't have access to the service code base.

\begin{listing}[h]
	\bashFile{\sourceDir/bash-oc-service.sh}
	\caption{Shell script for managing a service via the CLI}
	\label{ls:esboi-openshift-oc-service}
\end{listing}

The following chapter will evaluate and analyze the implemented prototype, if the prototype fulfills the specifications of Chapter \vref{cha:esboc}, and if the prototype is a valid representation for an ESB in Openshift.


